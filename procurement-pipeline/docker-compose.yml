services:
  # OLTP Database for Master Data
  postgres:
    image: postgres:13
    container_name: procurement_postgres
    environment:
      POSTGRES_USER: admin
      POSTGRES_PASSWORD: password
      POSTGRES_DB: procurement_db
    ports:
      - "5432:5432"
    volumes:
      - ./sql/postgres:/docker-entrypoint-initdb.d
    networks:
      - procurement_network

  # HDFS Namenode
  namenode:
    image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
    container_name: procurement_namenode
    hostname: namenode
    environment:
      - CLUSTER_NAME=procurement
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
    ports:
      - "9870:9870"
      - "9000:9000"
    volumes:
      - hdfs_namenode_data:/hadoop/dfs/name
    networks:
      - procurement_network

  # HDFS Datanode
  datanode:
    image: bde2020/hadoop-datanode:2.0.0-hadoop3.2.1-java8
    container_name: procurement_datanode
    hostname: datanode
    environment:
      - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
      - HDFS_CONF_dfs_replication=1
    volumes:
      - hdfs_datanode_data:/hadoop/dfs/data
    networks:
      - procurement_network
    depends_on:
      - namenode

  # Trino Query Engine (formerly Presto)
  trino:
    image: trinodb/trino:latest
    container_name: procurement_trino
    ports:
      - "8080:8080"
    volumes:
      - ./config/trino:/etc/trino/catalog
      - ./config/trino-config:/etc/trino
      - ./data/raw:/data/raw:ro
    networks:
      - procurement_network
    depends_on:
      - postgres
      - namenode
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/v1/info"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s

  # pgAdmin - PostgreSQL Web Interface
  pgadmin:
    image: dpage/pgadmin4:latest
    container_name: procurement_pgadmin
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports:
      - "5050:80"
    networks:
      - procurement_network
    depends_on:
      - postgres

  # Airflow - Workflow Orchestration
  airflow:
    image: apache/airflow:2.7.3-python3.10
    container_name: procurement_airflow
    environment:
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
      - AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://admin:password@postgres:5432/airflow_db
      - AIRFLOW__CORE__FERNET_KEY=h5tiQa3Zglp7i8PooALe7ylgjcPr87vyfQbOrS_EHOI=
      - AIRFLOW__CORE__LOAD_EXAMPLES=False
      - AIRFLOW__WEBSERVER__SECRET_KEY=procurement-secret-key-2026
      - AIRFLOW__CORE__DAGS_FOLDER=/opt/airflow/dags
      - AIRFLOW__LOGGING__BASE_LOG_FOLDER=/opt/airflow/logs
      - _AIRFLOW_DB_MIGRATE=true
      - _AIRFLOW_WWW_USER_CREATE=true
      - _AIRFLOW_WWW_USER_USERNAME=admin
      - _AIRFLOW_WWW_USER_PASSWORD=admin
    ports:
      - "8081:8080"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./scripts:/opt/airflow/scripts:ro
      - ./data:/opt/airflow/data
    networks:
      - procurement_network
    depends_on:
      - postgres
      - trino
    command: >
      bash -c "
        pip install pandas trino psycopg2-binary &&
        airflow db migrate &&
        airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com || true &&
        airflow webserver & airflow scheduler
      "
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5

networks:
  procurement_network:
    driver: bridge

volumes:
  hdfs_namenode_data:
  hdfs_datanode_data:
